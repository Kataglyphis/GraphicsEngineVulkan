#version 460

#extension GL_EXT_ray_query : require
#extension GL_EXT_nonuniform_qualifier : enable
#extension GL_GOOGLE_include_directive : enable
#extension GL_EXT_scalar_block_layout : enable

#extension GL_EXT_shader_explicit_arithmetic_types_int64 : require
#extension GL_EXT_buffer_reference2 : require

#include "../common/raycommon.glsl"

#include "../../../include/common/host_device_shared_vars.h"

#include "../brdf/unreal4.glsl"
#include "../brdf/disney.glsl"
#include "../brdf/pbrBook.glsl"
#include "../brdf/phong.glsl"
#include "../brdf/frostbite.glsl"

#include "../../../include/renderer/SceneUBO.h"
#include "../../../include/renderer/GlobalUBO.h"
#include "../../../include/renderer/pushConstants/PushConstantPathTracing.h"
#include "../../../include/scene/ObjMaterial.h"
#include "../../../include/scene/Vertex.h"
#include "../../../include/scene/ObjectDescription.h"

//layout(local_size_x_id = 0, local_size_y_id = 1, local_size_z_id = 2) in;
layout(local_size_x = 16, local_size_y = 8, local_size_z = 1) in;

layout (set = 0, binding = globalUBO_BINDING) uniform _GlobalUBO {
    GlobalUBO globalUBO;
};

layout (set = 0, binding = sceneUBO_BINDING) uniform _SceneUBO {
    SceneUBO sceneUBO;
};
layout(set = 0, binding = OBJECT_DESCRIPTION_BINDING, scalar) buffer ObjectDescription_ {
    ObjectDescription i[];
} object_description;

layout(set = 0, binding = SAMPLER_BINDING) uniform sampler texture_sampler[MAX_TEXTURE_COUNT];
layout(set = 0, binding = TEXTURES_BINDING) uniform texture2D tex[MAX_TEXTURE_COUNT];

layout(set = 1, binding = TLAS_BINDING) uniform accelerationStructureEXT TLAS;
layout(set = 1, binding = OUT_IMAGE_BINDING, rgba8) uniform image2D image; 

layout(buffer_reference, scalar) buffer Vertices {
    Vertex v[]; 
}; // Positions of an object

layout(buffer_reference, scalar) buffer Indices {
    ivec3 i[]; 
}; // Triangle indices

layout(buffer_reference, scalar) buffer MaterialIDs {
    int i[]; 
}; // per triangle material id

layout(buffer_reference, scalar) buffer Materials {
	ObjMaterial m[]; 
}; // all materials of .obj

layout(push_constant) uniform _PushConstantPathTracing {
    PushConstantPathTracing pc_ray;
};

// Steps the RNG and returns a floating-point value between 0 and 1 inclusive.
float stepAndOutputRNGFloat(inout uint rngState)
{
  // Condensed version of pcg_output_rxs_m_xs_32_32, with simple conversion to floating-point [0,1].
  rngState  = rngState * 747796405 + 1;
  uint word = ((rngState >> ((rngState >> 28) + 4)) ^ rngState) * 277803737;
  word      = (word >> 22) ^ word;
  return float(word) / 4294967295.0f;
}

struct HitInfo
{
  vec3 color;
  vec3 worldPosition;
  vec3 worldNormal;
};

HitInfo getObjectHitInfo(rayQueryEXT rayQuery)
{
    const int instanceCustomIndex = rayQueryGetIntersectionInstanceCustomIndexEXT(rayQuery, true);
    const mat4x3 objToWorld =  rayQueryGetIntersectionObjectToWorldEXT(rayQuery, true);

    ObjectDescription obj_res   = object_description.i[instanceCustomIndex];        // array of all object descriptions
    Indices indices             = Indices(obj_res.index_address);                   // array of all indices
    Vertices vertices           = Vertices(obj_res.vertex_address);                 // array of all vertices
    MaterialIDs materialIDs     = MaterialIDs(obj_res.material_index_address);      // array of per face material indices
    Materials materials		    = Materials(obj_res.material_address);			    // array of all materials

    HitInfo result;
    // Get the ID of the triangle
    const int primitiveID = rayQueryGetIntersectionPrimitiveIndexEXT(rayQuery, true);

    // Get the indices of the vertices of the triangle
    const ivec3 i = indices.i[primitiveID];

    // Get the vertices of the triangle
    const Vertex v0 = vertices.v[i.x];
    const Vertex v1 = vertices.v[i.x];
    const Vertex v2 = vertices.v[i.x];

    // Get the barycentric coordinates of the intersection
    vec3 barycentrics = vec3(0.0, rayQueryGetIntersectionBarycentricsEXT(rayQuery, true));
    barycentrics.x    = 1.0 - barycentrics.y - barycentrics.z;

    // Compute the coordinates of the intersection
    const vec3 objectPos = v0.pos * barycentrics.x + v1.pos * barycentrics.y + v2.pos * barycentrics.z;
    result.worldPosition = vec3(objToWorld * vec4(objectPos, 1.0f));

    //compute normal at hit position 
    const vec3 normal_hit = v0.normal * barycentrics.x + v1.normal * barycentrics.y + v2.normal * barycentrics.z;
    const vec3 world_normal_hit = normalize(vec3(objToWorld * vec4(normal_hit,1.0f)));
    // For the main tutorial, object space is the same as world space:
    result.worldNormal = world_normal_hit;

    vec2 texture_coordinates =  v0.texture_coords * barycentrics.x +
                                v1.texture_coords * barycentrics.y +
                                v2.texture_coords * barycentrics.z;
    
    // material id is stored per primitive
    vec3 ambient = vec3(0.f);
    int texture_id = materials.m[materialIDs.i[primitiveID]].textureID;
    ambient += texture(sampler2D(tex[texture_id], texture_sampler[texture_id]), texture_coordinates).xyz;

    result.color = ambient;

    return result;
}


void main() {

    const uvec2 resolution = uvec2(pc_ray.width, pc_ray.height);
    const uvec2 pixel = gl_GlobalInvocationID.xy;

    // If the pixel is outside of the image, don't do anything:
    if((pixel.x >= resolution.x) || (pixel.y >= resolution.y))
    {
    return;
    }

    // State of the random number generator.
    uint rngState = resolution.x * pixel.y + pixel.x;  // Initial seed

    // The sum of the colors of all of the samples.
    vec3 summedPixelColor = vec3(0.0);

    // Limit the kernel to trace at most 64 samples.
    const int NUM_SAMPLES = 4;
    for(int sampleIdx = 0; sampleIdx < NUM_SAMPLES; sampleIdx++)
    {
        // vec4(0,0,0,1) in homogenous coordinates hints that it is the position in the origin
        // assumption: origin is the standpoint from the viewer
        // the inverse gets us the actual world space position
        vec4 rayOrigin = inverse(globalUBO.view) * vec4(0, 0, 0, 1);
       // do not forget to invert the y-coord since we are in vulkan
        const vec2 randomPixelCenter = vec2(pixel) + vec2(stepAndOutputRNGFloat(rngState), stepAndOutputRNGFloat(rngState));
        vec2 randomPixelCenterUV = randomPixelCenter / resolution;
        vec2 randomPixelCenterCS = randomPixelCenterUV * 2.0f - 1.0f;

        vec4 target = inverse(globalUBO.projection) * vec4( randomPixelCenterCS.x, 
                                                            -randomPixelCenterCS.y, 
                                                            1, 
                                                            1);

        vec4 rayDirection = inverse(globalUBO.view) * vec4(normalize(target.xyz), 0);

        vec3 accumulatedRayColor = vec3(1.0);  // The amount of light that made it to the end of the current ray.

        // Limit the kernel to trace at most 32 segments.
        for(int tracedSegments = 0; tracedSegments < 4; tracedSegments++)
        {
            // Trace the ray and see if and where it intersects the scene!
            // First, initialize a ray query object:
            rayQueryEXT rayQuery;
            rayQueryInitializeEXT(rayQuery,             // Ray query
                                TLAS,                   // Top-level acceleration structure
                                gl_RayFlagsOpaqueEXT,  // Ray flags, here saying "treat all geometry as opaque"
                                0xFF,                  // 8-bit instance mask, here saying "trace against all instances"
                                rayOrigin.xyz,             // Ray origin
                                0.0,                   // Minimum t-value
                                rayDirection.xyz,          // Ray direction
                                10000.0);              // Maximum t-value

            // Start traversal, and loop over all ray-scene intersections. When this finishes,
            // rayQuery stores a "committed" intersection, the closest intersection (if any).
            while(rayQueryProceedEXT(rayQuery))
            {
            }

            // Get the type of committed (true) intersection - nothing, a triangle, or
            // a generated object
            if(rayQueryGetIntersectionTypeEXT(rayQuery, true) == gl_RayQueryCommittedIntersectionTriangleEXT) {
                // Ray hit a triangle
                HitInfo hitInfo = getObjectHitInfo(rayQuery);

                // Apply color absorption
                accumulatedRayColor *= hitInfo.color;

                // Flip the normal so it points against the ray direction:
                hitInfo.worldNormal = faceforward(hitInfo.worldNormal, rayDirection.xyz, hitInfo.worldNormal);

                // Start a new ray at the hit position, but offset it slightly along the normal:
                rayOrigin = vec4(hitInfo.worldPosition + 0.0001 * hitInfo.worldNormal,1.0f);

                // For a random diffuse bounce direction, we follow the approach of
                // Ray Tracing in One Weekend, and generate a random point on a sphere
                // of radius 1 centered at the normal. This uses the random_unit_vector
                // function from chapter 8.5:
                const float theta   = 6.2831853 * stepAndOutputRNGFloat(rngState);  // Random in [0, 2pi]
                const float u       = 2.0 * stepAndOutputRNGFloat(rngState) - 1.0;  // Random in [-1, 1]
                const float r       = sqrt(1.0 - u * u);
                rayDirection.xyz    = hitInfo.worldNormal + vec3(r * cos(theta), r * sin(theta), u);

            } else {

            // Ray hit the sky
            //accumulatedRayColor *= pc_ray.clearColor.xyz;

            // Sum this with the pixel's other samples.
            // (Note that we treat a ray that didn't find a light source as if it had
            // an accumulated color of (0, 0, 0)).
            summedPixelColor += accumulatedRayColor;

            break;

            }
        }
    }

    imageStore(image, ivec2(pixel), vec4(summedPixelColor / float(NUM_SAMPLES), 1.0));

}